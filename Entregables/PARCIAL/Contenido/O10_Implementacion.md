# 10. IMPLEMENTACIÃ“N TÃ‰CNICA EN HORTONWORKS

## 10.1. Ingesta inicial a HDFS

En esta secciÃ³n se describe el procedimiento realizado para la ingesta inicial de archivos al sistema distribuido de archivos de Hadoop (HDFS) dentro del entorno Hortonworks.  

El objetivo es automatizar la transferencia de archivos locales (en formatos .csv y .xlsx) hacia la zona /data/raw/ del HDFS, garantizando trazabilidad y reproducibilidad del proceso.  

---

### 10.1.1. ConfiguraciÃ³n de conexiÃ³n SSH entre host y Hortonworks

Para establecer una comunicaciÃ³n segura entre la mÃ¡quina anfitriona (Windows) y la mÃ¡quina virtual (Hortonworks Sandbox), se configurÃ³ un acceso mediante llaves SSH.  

**PASO 1: CreaciÃ³n de la carpeta para almacenar la llave**  
CÃ³digo:
```bash
mkdir $env:USERPROFILE\.ssh  
```
EjecuciÃ³n:  
![](O10_1.png) 

---

**PASO 2: GeneraciÃ³n de las llaves RSA de 4096 bits**  
CÃ³digo:
```bash
ssh-keygen -t rsa -b 4096 -f $env:USERPROFILE\.ssh\horton_id_rsa  
```

EjecuciÃ³n:  
![](O10_2.png)  

---

**PASO 3: VerificaciÃ³n de los archivos generados**  
CÃ³digo:
```bash  
ls $env:USERPROFILE\.ssh  
```

EjecuciÃ³n:  
![](O10_3.png) 

Donde:  
- horton_id_rsa corresponde a la llave privada, almacenada localmente.  
- horton_id_rsa.pub es la llave pÃºblica, que se copia al servidor remoto.  

---

**PASO 4: ObtenciÃ³n de la direcciÃ³n IP de la mÃ¡quina virtual**  
CÃ³digo:
```bash  
ip a  
```

EjecuciÃ³n:  
![](O10_4.png) 

---

**PASO 5: ConexiÃ³n al entorno virtual Hortonworks desde PowerShell**  
CÃ³digo:
```bash  
ssh -p 2222 root@127.0.0.1  
```

EjecuciÃ³n:  
![](O10_5.png)

---

**PASO 6: Registro de la llave pÃºblica en la VM**  
CÃ³digo:
```bash  
mkdir -p ~/.ssh  
cat /root/horton_id_rsa.pub >> ~/.ssh/authorized_keys  
chmod 700 ~/.ssh  
chmod 600 ~/.ssh/authorized_keys  
```

EjecuciÃ³n:  
![](O10_6.png)  

---

### 10.1.2. AutomatizaciÃ³n de carga con script Python

Para optimizar la carga de archivos al HDFS, se desarrollÃ³ un script en Python denominado subir_a_hdfs.py.  

Este script automatiza la conversiÃ³n de archivos Excel a CSV, la transferencia a la mÃ¡quina virtual mediante scp, y finalmente la carga en HDFS.  

**CÃ³digo:

```python  
ImportaciÃ³n de librerÃ­as  
import os  
import re  
import unicodedata  
import subprocess  
import pandas as pd  

ConfiguraciÃ³n de parÃ¡metros  
KEY_PATH = r"C:\Users\Lenovo\.ssh\horton_id_rsa"  
LOCAL_DIR = r"C:\Inteligencia_Negocios\Archivos\Descargados"  
REMOTE_DIR = "/root/hdfs_upload"  
HDFS_DIR = "/data/raw/"  
SSH_CONN = "root@127.0.0.1"  
SSH_PORT = "2222"  
```
---

### 10.1.3. ConversiÃ³n de archivos Excel a CSV

El script incluye una funciÃ³n que normaliza nombres de archivos y convierte las hojas de Excel en archivos CSV independientes, preservando las tildes y caracteres especiales.  

```python 
def limpiar_nombre(nombre):  
â€ƒnfkd = unicodedata.normalize("NFKD", nombre)  
â€ƒsin_tildes = "".join([c for c in nfkd if not unicodedata.combining(c)])  
â€ƒsin_espacios = sin_tildes.replace(" ", "_")  
â€ƒlimpio = re.sub(r"[^A-Za-z0-9._-]", "", sin_espacios)  
â€ƒreturn limpio  

Cada archivo Excel (.xls o .xlsx) es procesado hoja por hoja y exportado a formato CSV:  

ðŸ“„ Convirtiendo archivos Excel a CSV...  

converted_files = []  
for f in files:  
â€ƒpath = os.path.join(LOCAL_DIR, f)  
â€ƒif f.endswith((".xls", ".xlsx")):  
â€ƒâ€ƒprint(f" -> {f}")  
â€ƒâ€ƒxls = pd.ExcelFile(path)  
â€ƒâ€ƒfor sheet in xls.sheet_names:  
â€ƒâ€ƒâ€ƒdf = pd.read_excel(xls, sheet_name=sheet)  
â€ƒâ€ƒâ€ƒclean_sheet = limpiar_nombre(sheet)  
â€ƒâ€ƒâ€ƒnew_name = limpiar_nombre(f"{os.path.splitext(f)[0]}_{clean_sheet}.csv")  
â€ƒâ€ƒâ€ƒnew_path = os.path.join(LOCAL_DIR, new_name)  
â€ƒâ€ƒâ€ƒdf.to_csv(new_path, index=False)  
â€ƒâ€ƒâ€ƒconverted_files.append(new_name)  
â€ƒâ€ƒâ€ƒprint(f"â€ƒ|-> Hoja '{sheet}' -> {new_name}")  
â€ƒelse:  
â€ƒâ€ƒconverted_files.append(f)  
```
---

### 10.1.4. Subida automÃ¡tica a HDFS y verificaciÃ³n

Una vez convertidos los archivos, el script automatiza su transferencia y posterior carga al HDFS.  

**Copia de archivos a la mÃ¡quina virtual:**  
```python 
ðŸšš Copiando archivos a la VM (sandbox)...  

subprocess.run(  
â€ƒ["ssh", "-p", SSH_PORT, "-i", KEY_PATH, SSH_CONN, f"mkdir -p {REMOTE_DIR}"],  
â€ƒcheck=True,  
)  

for f in converted_files:  
â€ƒlocal_path = os.path.join(LOCAL_DIR, f)  
â€ƒprint(f"â†’ Subiendo {f}")  
â€ƒsubprocess.run(  
â€ƒâ€ƒ[  
â€ƒâ€ƒâ€ƒ"scp",  
â€ƒâ€ƒâ€ƒ"-P",  
â€ƒâ€ƒâ€ƒSSH_PORT,  
â€ƒâ€ƒâ€ƒ"-i",  
â€ƒâ€ƒâ€ƒKEY_PATH,  
â€ƒâ€ƒâ€ƒlocal_path,  
â€ƒâ€ƒâ€ƒf"{SSH_CONN}:{REMOTE_DIR}/",  
â€ƒâ€ƒ],  
â€ƒcheck=True,  
â€ƒ)  
```
**CreaciÃ³n de carpeta en HDFS y carga final:**  
```python 
ðŸ“¦ Subiendo archivos al HDFS...  

cmd_create_dir = f"hdfs dfs -mkdir -p {HDFS_DIR}"  
cmd_put = f'for f in {REMOTE_DIR}/*; do hdfs dfs -put -f "$f" {HDFS_DIR}; done'  

subprocess.run(  
â€ƒ["ssh", "-p", SSH_PORT, "-i", KEY_PATH, SSH_CONN, cmd_create_dir], check=True  
)  
subprocess.run(["ssh", "-p", SSH_PORT, "-i", KEY_PATH, SSH_CONN, cmd_put], check=True)  

âœ… Â¡Archivos subidos correctamente a HDFS en /data/raw/!  
```